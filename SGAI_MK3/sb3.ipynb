{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import stable_baselines3 as sb3\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "from Board import Board\n",
    "from Player import GovernmentPlayer\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZombieEnvironment(gym.Env):\n",
    "    ACTION_SPACE = tuple(range(8))\n",
    "    ACTION_MAPPINGS = {\n",
    "        0: \"movebiteUp\",\n",
    "        1: \"movebiteDown\",\n",
    "        2: \"movebiteLeft\",\n",
    "        3: \"movebiteRight\",\n",
    "    }\n",
    "    SIZE = (6, 6)\n",
    "\n",
    "    def __init__(\n",
    "        self, max_timesteps: int = 300, have_enemy_player: bool = True\n",
    "    ) -> None:\n",
    "        self.max_timesteps = max_timesteps\n",
    "        self.reset()\n",
    "        self.total_timesteps = 0\n",
    "        self.total_invalid_moves = 0\n",
    "        self.have_enemy_player = have_enemy_player\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self.observation_space = gym.spaces.Box(-0.5, 0.5, (36,))\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = Board(ZombieEnvironment.SIZE, \"Zombie\")\n",
    "        self.board.populate(num_zombies=1)\n",
    "        self.enemyPlayer = GovernmentPlayer()\n",
    "        self.done = False\n",
    "\n",
    "        # coordinates of the first zombie\n",
    "        self.agentPosition = self.board.indexOf(True)\n",
    "\n",
    "        # useful for metrics\n",
    "        self.max_number_of_zombies = 1\n",
    "        self.episode_invalid_actions = 0\n",
    "        self.episode_reward = 0\n",
    "        self.episode_timesteps = 0\n",
    "\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action: int):\n",
    "        action_name = ZombieEnvironment.ACTION_MAPPINGS[action]\n",
    "\n",
    "        # first, try to move\n",
    "        valid, new_pos = self.board.actionToFunction[\"move\" + action_name[8:]](\n",
    "            self.board.toCoord(self.agentPosition)\n",
    "        )\n",
    "        if valid:\n",
    "            self.agentPosition = new_pos\n",
    "            action_name = \"move\"\n",
    "        else:  # bite variation\n",
    "            dest_coord = list(self.board.toCoord(self.agentPosition))\n",
    "            if \"Up\" in action_name:\n",
    "                dest_coord[1] -= 1\n",
    "            elif \"Down\" in action_name:\n",
    "                dest_coord[1] += 1\n",
    "            elif \"Right\" in action_name:\n",
    "                dest_coord[0] += 1\n",
    "            else:\n",
    "                dest_coord[0] -= 1\n",
    "            valid, _ = self.board.actionToFunction[\"bite\"](dest_coord)\n",
    "            if valid:\n",
    "                action_name = \"bite\"\n",
    "\n",
    "        won = None\n",
    "        # do the opposing player's action if the action was valid.\n",
    "        if valid:\n",
    "            _action, coord = self.enemyPlayer.get_move(self.board)\n",
    "            if not _action:\n",
    "                self.done = True\n",
    "                won = True\n",
    "            else:\n",
    "                if self.have_enemy_player:\n",
    "                    self.board.actionToFunction[_action](coord)\n",
    "            self.board.update()\n",
    "\n",
    "        # see if the game is over\n",
    "        if not self.board.States[\n",
    "            self.agentPosition\n",
    "        ].person.isZombie:  # zombie was cured\n",
    "            self.done = True\n",
    "            won = False\n",
    "        if not self.board.is_move_possible_at(self.agentPosition):  # no move possible\n",
    "            self.done = True\n",
    "        if self.episode_timesteps > self.max_timesteps:\n",
    "            self.done = True\n",
    "        if not valid:\n",
    "            self.done = True\n",
    "\n",
    "        # get obs, reward, done, info\n",
    "        obs, reward, done, info = (\n",
    "            self._get_obs(),\n",
    "            self._get_reward(action_name, valid, won),\n",
    "            self._get_done(),\n",
    "            self._get_info(),\n",
    "        )\n",
    "\n",
    "        # update the metrics\n",
    "        self.episode_reward += reward\n",
    "        if not valid:\n",
    "            self.episode_invalid_actions += 1\n",
    "            self.total_invalid_moves += 1\n",
    "        self.episode_timesteps += 1\n",
    "        self.max_number_of_zombies = max(\n",
    "            self.board.num_zombies(), self.max_number_of_zombies\n",
    "        )\n",
    "        self.total_timesteps += 1\n",
    "\n",
    "        # return the obs, reward, done, info\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {}\n",
    "\n",
    "    def _get_done(self):\n",
    "        return self.done\n",
    "\n",
    "    def _get_reward(self, action_name: str, was_valid: bool, won: bool):\n",
    "        \"\"\"\n",
    "        Gonna try to return reward between [-1, 1]\n",
    "        \"\"\"\n",
    "        if not was_valid:\n",
    "            return -1\n",
    "        if won is True:\n",
    "            return 1\n",
    "        if won is False:\n",
    "            return -0.1\n",
    "        if \"bite\" in action_name:\n",
    "            return 0.9\n",
    "        return -0.01  # this is the case where it was move\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"\n",
    "        Is based off the assumption that 5 is not in the returned board.\n",
    "        Uses 5 as the key for current position.\n",
    "        \"\"\"\n",
    "        AGENT_POSITION_CONSTANT = 5\n",
    "        ret = self.board.get_board()\n",
    "        ret[self.agentPosition] = AGENT_POSITION_CONSTANT\n",
    "\n",
    "        # normalize observation to be be centered at 0\n",
    "        ret = np.array(ret, dtype=np.float32)\n",
    "        ret /= np.float32(AGENT_POSITION_CONSTANT)\n",
    "        ret -= np.float32(0.5)\n",
    "        return ret  # (36, )\n",
    "\n",
    "    def render(self):\n",
    "        import PygameFunctions as PF\n",
    "        import pygame\n",
    "\n",
    "        PF.run(self.board)\n",
    "        pygame.display.update()\n",
    "\n",
    "    def init_render(self):\n",
    "        import PygameFunctions as PF\n",
    "        import pygame\n",
    "\n",
    "        PF.initScreen(self.board)\n",
    "        pygame.display.update()\n",
    "\n",
    "    def close(self):\n",
    "        import pygame\n",
    "\n",
    "        pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ZombieEnvironment(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sb3.PPO(\"MlpPolicy\", env, tensorboard_log=\"tflogv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.learn(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "\n",
    "def watch_model(model, max_timesteps, render=False):\n",
    "    _env = ZombieEnvironment(max_timesteps)\n",
    "    done = False\n",
    "    obs = _env.reset()\n",
    "    if render:\n",
    "        _env.init_render()\n",
    "    actions = []\n",
    "    while not done:\n",
    "        if render:\n",
    "            _env.render()\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        actions.append(action)\n",
    "        obs, reward, done, info = _env.step(action)\n",
    "        time.sleep(0.2)\n",
    "    if render:\n",
    "        _env.render()\n",
    "        time.sleep(0.2)\n",
    "        _env.close()\n",
    "    print(Counter(actions).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_model(trained_model, 50, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = trained_model.learn(17500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.save(\"./saved_zombie_models/ppov2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = sb3.PPO.load(\"./saved_zombie_models/ppov2.zip\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a569b528fb1110d0d7d552dfd5bf7c0920d164754c3ee6d9fc5930b2e92fc65e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
